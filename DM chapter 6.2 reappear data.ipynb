{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''数据集重建\n",
    "首先，我们得把现有消息的编号及其类别保存下来。创建一个新的笔记本文件，指定接下来要用到的几个文件名。\n",
    "代码跟之前类似，只不过多了一个用来保存消息编号及其类别的文件。代码如下：\n",
    "'''\n",
    "import os\n",
    "input_filename = os.path.join(os.path.expanduser(\"~\"), \"Data\", \"twitter\", \"python_tweets.json\")\n",
    "labels_filename = os.path.join(os.path.expanduser(\"~\"), \"Data\", \"twitter\", \"python_classes.json\")\n",
    "replicable_dataset = os.path.join(os.path.expanduser(\"~\"), \"Data\", \"twitter\", \"replicable_dataset.json\")\n",
    "\n",
    "'''加载消息和类别，就跟我们在上一个笔记本文件中做的那样。'''\n",
    "import json\n",
    "tweets = []\n",
    "with open(input_filename) as inf:\n",
    "    for line in inf:\n",
    "        if len(line.strip()) == 0:\n",
    "            continue\n",
    "        tweets.append(json.loads(line))\n",
    "if os.path.exists(labels_filename):\n",
    "    with open(classes_filename) as inf:\n",
    "        labels = json.load(inf)\n",
    "\n",
    "'''同时遍历所有的消息及消息所属的类别，创建新数据集，将其保存到列表中。'''\n",
    "dataset = [(tweet['id'], label) for tweet, label in zip(tweets, labels)]\n",
    "\n",
    "\n",
    "'''最后，把结果保存到文件中。'''\n",
    "with open(replicable_dataset, 'w') as outf:\n",
    "    json.dump(dataset, outf)\n",
    "'''有了消息的编号和类别，我们就可以重建数据集。'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "tweet_filename = os.path.join(os.path.expanduser(\"~\"), \"Data\", \"twitter\", \"replicable_python_tweets.json\")\n",
    "labels_filename = os.path.join(os.path.expanduser(\"~\"), \"Data\", \"twitter\", \"replicable_python_classes.json\")\n",
    "replicable_dataset = os.path.join(os.path.expanduser(\"~\"), \"Data\", \"twitter\", \"replicable_dataset.json\")\n",
    "\n",
    "'''使用JSON从文件中加载消息编号及类别数据。'''\n",
    "import json\n",
    "with open(replicable_dataset) as inf:\n",
    "    tweet_ids = json.load(inf)\n",
    "\n",
    "'''\n",
    "只输出我们实际能用到的类别就显得尤为重要。具体做法是，首先，创建actual_labels列表存储我们能够再次从Twitter网站获取到的消息的类别。\n",
    "然后，创建字典，为消息的编号和类别建立起映射关系。\n",
    "'''\n",
    "actual_labels = []\n",
    "label_mapping = dict(tweet_ids)\n",
    "\n",
    "'''\n",
    "接下来，用twitter库根据消息编号采集消息。这可能要花点时间。导入前面用过的twitter库，创建授权令牌，用它来初始化twitter对象。\n",
    "'''\n",
    "import twitter\n",
    "consumer_key = \"<Your Consumer Key Here>\"\n",
    "consumer_secret = \"<Your Consumer Secret Here>\"\n",
    "access_token = \"<Your Access Token Here>\"\n",
    "access_token_secret = \"<Your Access Token Secret Here>\"\n",
    "authorization = twitter.OAuth(access_token, access_token_secret, consumer_key, consumer_secret)\n",
    "t = twitter.Twitter(auth=authorization)\n",
    "\n",
    "'''遍历并抽取所有的消息编号。'''\n",
    "all_ids = [tweet_id for tweet_id, label in tweet_ids]\n",
    "with open(tweets_filename, 'a') as output_file:\n",
    "    '''Twitter API允许我们一次只能获取100条消息。因此，每次遍历100条消息。'''\n",
    "    for start_index in range(0, len(tweet_ids), 100):\n",
    "        '''把这一批次的100个编号用逗号连接起来，便于下面使用Twitter的API根据编号查找消息。'''\n",
    "        id_string = \",\".join(str(i) for i in all_ids[start_index:start_index+100])\n",
    "        '''接着，调用Twitter定义的statuses/lookup方法，传入一批消息编号（已转换为字符串），以采集这些消息。'''\n",
    "        search_results = t.statuses.lookup(_id=id_string)\n",
    "        for tweet in search_results:\n",
    "            if 'text' in tweet:\n",
    "                output_file.write(json.dumps(tweet))\n",
    "                output_file.write(\"\\n\\n\")\n",
    "                '''\n",
    "                最后一步（仍然属于if模块），还需要保存当前遍历到的消息的类别。\n",
    "                获取消息类别要用到之前创建的label_mapping字典，根据消息编号查找即可。代码如下：\n",
    "                '''\n",
    "                actual_labels.append(label_mapping[tweet['id']])\n",
    "with open(labels_filename, 'w') as outf:\n",
    "    json.dump(actual_labels, outf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 9),\n",
       " ('for', 4),\n",
       " ('in', 4),\n",
       " ('to', 4),\n",
       " ('one', 4),\n",
       " ('of', 3),\n",
       " ('ring', 3),\n",
       " ('dark', 2),\n",
       " ('land', 2),\n",
       " ('mordor', 2)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"\"\"Three Rings for the Elven-kings under the sky,\n",
    "Seven for the Dwarf-lords in halls of stone,\n",
    "Nine for Mortal Men, doomed to die,\n",
    "One for the Dark Lord on his dark throne\n",
    "In the Land of Mordor where the Shadows lie.\n",
    "One Ring to rule them all, One Ring to find them,\n",
    "One Ring to bring them all and in the darkness bind them.\n",
    "In the Land of Mordor where the Shadows lie. \"\"\".lower()\n",
    "words = s.split()\n",
    "from collections import Counter\n",
    "c = Counter(words)\n",
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
